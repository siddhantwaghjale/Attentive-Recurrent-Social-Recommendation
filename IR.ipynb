{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "9PKD5ECZLLHy",
        "colab_type": "code",
        "outputId": "db91385b-7481-40f2-b334-4dd81e4c576c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iWPkPm2lQjXD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Input, SimpleRNN, Reshape, LSTM, Flatten\n",
        "\n",
        "\n",
        "def return_classes(df):\n",
        "    le = LabelEncoder()\n",
        "    le.fit(df)\n",
        "    classes = le.classes_.tolist()\n",
        "    return le.transform(df)\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/My Drive/IR/trial.csv\")\n",
        "\n",
        "\n",
        "data.columns = ['user_id', 'product_id', 'rating']\n",
        "\n",
        "# pd.to_numeric(data['user_id'])\n",
        "data.head()\n",
        "data.info()\n",
        "\n",
        "\n",
        "data.iloc[56000]\n",
        "\n",
        "\n",
        "\n",
        "X_data = data.iloc[:,:-1].values\n",
        "y_data = data.iloc[:,-1].values\n",
        "\n",
        "\n",
        "\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_data,y_data,test_size=0.1)\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "\n",
        "scaler = Normalizer().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "scaler = Normalizer().fit(X_val)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# X_train=X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
        "# y_train = np.reshape(y_train, (y_train.shape[0], 1, y_train.shape[1]))\n",
        "# y_val = np.reshape(y_val, (y_val.shape[0], 1, y_val.shape[1]))\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(1,2),return_sequences=True))\n",
        "model.summary()\n",
        "model.add(LSTM(4, input_shape=(2,),return_sequences=True))\n",
        "model.add(LSTM(4, input_shape=(1,2),return_sequences=False))\n",
        "# model.add(Dense(64, input_shape=(2,), activation='relu'))\n",
        "model.add(Dropout(0.05))\n",
        "# model.add(Reshape((1,4)))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train,y_train,epochs=100,validation_data=(X_val,y_val))\n",
        "\n",
        "\n",
        "ROW = 56000\n",
        "pred = np.expand_dims(data.iloc[ROW,:-1].values,axis=0)\n",
        "np.argmax(model.predict(pred))\n",
        "\n",
        "data.iloc[0,:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mXzX5VuhFF_j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Input, SimpleRNN, Reshape, LSTM, Flatten\n",
        "\n",
        "def return_classes(df):\n",
        "    le = LabelEncoder()\n",
        "    le.fit(df)\n",
        "    classes = le.classes_.tolist()\n",
        "    return le.transform(df)\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/My Drive/IR/gowalla_test.csv\")[:928670]\n",
        "data1 = pd.read_csv(\"/content/drive/My Drive/IR/trial.csv\")[:928670]\n",
        "# 928670\n",
        "\n",
        "data.columns = ['user_id', 'time', 'co-1', 'co-2', 'productid']\n",
        "data1.columns = ['user_id', 'product_id', 'rating']\n",
        "\n",
        "# pd.to_numeric(data['user_id'])\n",
        "data.head()\n",
        "data.info()\n",
        "\n",
        "# del data['time']\n",
        "\n",
        "X_data = data.iloc[:,:-1].values\n",
        "y_data = data1.iloc[:,-1].values\n",
        "\n",
        "\n",
        "\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_data,y_data,test_size=0.1)\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "\n",
        "scaler = Normalizer().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "scaler = Normalizer().fit(X_val)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# X_train=X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
        "# y_train = np.reshape(y_train, (y_train.shape[0], 1, y_train.shape[1]))\n",
        "# y_val = np.reshape(y_val, (y_val.shape[0], 1, y_val.shape[1]))\n",
        "\n",
        "# from collections import OrderedDict\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "\n",
        "# # minimum number of users we have scores for to average\n",
        "# min_users = 10\n",
        "\n",
        "# input_dir = 'ndcgs/'\n",
        "\n",
        "# # a list of input files\n",
        "# input_files = [ join( input_dir, f ) for f in listdir( input_dir ) if isfile( join( input_dir, f )) and f.endswith( '.pkl' ) ]\n",
        "\n",
        "# for i_f in input_files:\n",
        "# \tprint i_f\n",
        "\t\n",
        "# #\n",
        "\n",
        "# ndcgs = [ pickle.load( open( i_f, 'rb' ))['ndcgs'] for i_f in input_files ]\n",
        "\n",
        "# for i in range( len( ndcgs )):\n",
        "# \tassert( sorted( ndcgs[i].keys()) == ndcgs[i].keys())\n",
        "\n",
        "# mean_ndcgs = [ \n",
        "# \tOrderedDict( { k: sum( v ) / len( v ) for k, v in x.items() if len( v ) >= min_users } ) \n",
        "# \tfor x in ndcgs ]\n",
        "\n",
        "# colors = [ 'g', 'b', 'r', 'k', 'y' ]\n",
        "\n",
        "# for i, n in enumerate( mean_ndcgs ):\n",
        "# \tplt.plot( n.keys(), n.values(), colors[i] )\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(1,4),return_sequences=True))\n",
        "model.summary()\n",
        "model.add(LSTM(4,return_sequences=True))\n",
        "model.add(LSTM(4,return_sequences=False))\n",
        "# model.add(Dense(64, input_shape=(2,), activation='relu'))\n",
        "model.add(Dropout(0.05))\n",
        "# model.add(Reshape((1,4)))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train,y_train,epochs=1,validation_data=(X_val,y_val))\n",
        "\n",
        "def dcg_at_k(r, k, method=0):\n",
        "    \"\"\"Score is discounted cumulative gain (dcg)\n",
        "    Relevance is positive real values.  Can use binary\n",
        "    as the previous methods.\n",
        "    Example from\n",
        "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "        k: Number of results to consider\n",
        "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "    Returns:\n",
        "        Discounted cumulative gain\n",
        "    \"\"\"\n",
        "    r = np.asfarray(r)[:k]\n",
        "    if r.size:\n",
        "        if method == 0:\n",
        "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
        "        elif method == 1:\n",
        "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
        "        else:\n",
        "            raise ValueError('method must be 0 or 1.')\n",
        "    return 0.\n",
        "\n",
        "def ndcg_at_k(r, k=20, method=1):\n",
        "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
        "    Relevance is positive real values.  Can use binary\n",
        "    as the previous methods.\n",
        "    Example from\n",
        "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
        "\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "        k: Number of results to consider\n",
        "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "    Returns:\n",
        "        Normalized discounted cumulative gain\n",
        "    \"\"\"\n",
        "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    return dcg_at_k(r, k, method) / dcg_max\n",
        "  \n",
        "\n",
        "from matplotlib import pyplot\n",
        "  \n",
        "ndcg_values = []\n",
        "i_val = []\n",
        "for i in range (0, 10) :\n",
        "  ndcg_values.append(ndcg_at_k(X_val[1], i))\n",
        "  i_val.append(i)\n",
        "  \n",
        "pyplot.plot(i_val, ndcg_values, marker='.')\n",
        "pyplot.show()\n",
        "#   print(ndcg_at_k(X_val[1], i))\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "probs = model.predict_proba(X_val)\n",
        "# keep probabilities for the positive outcome only\n",
        "probs = probs[:, 1]\n",
        "# predict class values\n",
        "yhat = model.predict(X_val)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_val.argmax(axis=1), probs)\n",
        "# calculate F1 score\n",
        "# f1 = f1_score(y_val.argmax(axis=1), yhat)\n",
        "# calculate precision-recall AUC\n",
        "auc = auc(recall, precision)\n",
        "# calculate average precision score\n",
        "ap = average_precision_score(y_val.argmax(axis=1), probs)\n",
        "print(' auc=%.3f ap=%.3f' % ( auc, ap))\n",
        "# plot no skill\n",
        "pyplot.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
        "# plot the precision-recall curve for the model\n",
        "pyplot.plot(recall, precision, marker='.')\n",
        "# show the plot\n",
        "pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7GkEsNQlnJXC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('drive/My Drive/IR/ratings_data.txt','r') as csvinput:\n",
        "  with open('drive/My Drive/IR/trial.csv', 'w') as csvoutput:\n",
        "    writer = csv.writer(csvoutput)\n",
        "    reader = csv.reader(csvinput, delimiter=' ')\n",
        "\n",
        "    for row in reader:\n",
        "      all = []\n",
        "      all.append(row[0])\n",
        "      all.append(row[1])\n",
        "      all.append(1)\n",
        "\n",
        "      writer.writerow(all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kUdNy8DN12M4",
        "colab_type": "code",
        "outputId": "c553a1a9-d7f6-4772-d7e7-87ce7b3a1afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "maxi, maxj = 0, 0\n",
        "with open('drive/My Drive/IR/trial.csv','r') as inp :\n",
        "  reader = csv.reader(inp)\n",
        "  for row in reader :\n",
        "    if int(row[0]) > maxi :\n",
        "      maxi = int(row[0])\n",
        "    if int(row[1]) > maxj :\n",
        "      maxj = int(row[1])\n",
        "      \n",
        "print(maxi, maxj)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49289 139738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qyvG3WAI2Q4X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('drive/My Drive/IR/trial1.csv', 'w') as inp :\n",
        "  writer = csv.writer(inp)\n",
        "  for i in range(1, 4) :\n",
        "    for j in range(1, 200) :\n",
        "      arr = [i, j, 0]\n",
        "      print(arr)\n",
        "      writer.writerow(arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQmubjrG3jCi",
        "colab_type": "code",
        "outputId": "270f078a-170a-427c-afde-b593af8fe6d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import csv, sys\n",
        "arr = {}\n",
        "with open('drive/My Drive/IR/trial.csv', 'r') as inputf :\n",
        "  reader = csv.reader(inputf)\n",
        "  for row in reader :\n",
        "    if int(row[0]) not in arr :\n",
        "      arr[int(row[0])] = []\n",
        "    arr[int(row[0])].append(int(row[1]))\n",
        "    \n",
        "with open('drive/My Drive/IR/trial.csv', 'a') as outf :\n",
        "  writer = csv.writer(outf)\n",
        "  for i in range(1, 49289) :\n",
        "    if i not in arr :\n",
        "      continue\n",
        "    for j in range(1, 10000) :\n",
        "      if j in arr[i] :\n",
        "        continue\n",
        "      temp = [i, j, 0]\n",
        "      writer.writerow(temp)\n",
        "      print('\\r' + str(i) + ' ' + str(j), end=\"\")\n",
        "      sys.stdout.flush()\n",
        "      \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39 2948"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "897aVoSz9Ifq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('drive/My Drive/IR/trial.csv', 'r') as inputf :\n",
        "  reader = csv.reader(inputf)\n",
        "  for row in reader :\n",
        "    if row[2] == '0' :\n",
        "      print(row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GAZQLh7U-X2X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "import time\n",
        "with open('drive/My Drive/IR/Gowalla_totalCheckins.txt', 'r') as inputf :\n",
        "  with open('drive/My Drive/IR/gowalla_test.csv', 'w') as csvoutput:\n",
        "    reader = csv.reader(inputf, delimiter='\\t')\n",
        "    writer = csv.writer(csvoutput)\n",
        "    for row in reader :\n",
        "  #     print(row)\n",
        "      str1 = row[1]\n",
        "      year = str1[:4]\n",
        "      month = str1[5:7]\n",
        "      day = str1[8:10]\n",
        "      hour = str1[11:13]\n",
        "      mini = str1[14:16]\n",
        "      sec = str1[17:19]\n",
        "      s = day+'/'+month+'/'+year+' '+hour+':'+mini+':'+sec\n",
        "  #     print(s)\n",
        "      d = datetime.strptime(s, \"%d/%m/%Y %H:%M:%S\")\n",
        "      t = time.mktime(d.timetuple())\n",
        "      arr = [row[0], t, row[2], row[3], row[4]]\n",
        "      writer.writerow(arr)\n",
        "  #     print(year, month, day, hour, mini, sec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EUUpGWfbw6qr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}